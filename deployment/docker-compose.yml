#version: "3.8"
services:
  kafka:
    image: bitnamilegacy/kafka:3.5.1
    container_name: kafka
    environment:
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
      - ALLOW_PLAINTEXT_LISTENER=yes
    ports:
      - "9092:9092"
    networks:
      - icsnet
    volumes:
      - kafka_data:/bitnami/kafka
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

  influxdb:
    image: influxdb:latest
    container_name: influxdb
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=adminpass
      - DOCKER_INFLUXDB_INIT_ORG=ucs
      - DOCKER_INFLUXDB_INIT_BUCKET=swat_db
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=admintoken123
    ports:
      - "8086:8086"
    networks:
      - icsnet
    volumes:
      - influxdb_data:/var/lib/influxdb2
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8086/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_SMTP_ENABLED=true
      - GF_SMTP_HOST=smtp.gmail.com:587
      - GF_SMTP_USER=grafana.alert.dummy@gmail.com
      - GF_SMTP_PASSWORD=qsra tjgx gfmi flnf
      - GF_SMTP_FROM_ADDRESS=grafana.alert.dummy@gmail.com
      - GF_SMTP_FROM_NAME=Grafana Alerts
      - GF_SMTP_STARTTLS_ENABLED=true
      - GF_SMTP_SKIP_VERIFY=false
      # optional but nice:
      - GF_ALERTING_ENABLED=true
    ports:
      - "3000:3000"
    networks:
      - icsnet
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus/:/etc/prometheus/:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - icsnet

  explainability:
    build:
      context: ..
      dockerfile: explainability/Dockerfile
    container_name: explainability
    depends_on:
      - kafka
      - influxdb
    environment:
      KAFKA_BOOTSTRAP: "kafka:9092"
      KAFKA_TOPIC: "ics-sensor-data"
      INFLUX_URL: "http://influxdb:8086"
      INFLUX_ORG: "ucs"
      INFLUX_TOKEN: "admintoken123"
      INFLUX_BUCKET: "explain_db"
    networks:
      - icsnet
    restart: on-failure
    ports:
      - "9110:9109"

  producer:
    build:
      context: ../
      dockerfile: producer/Dockerfile
    container_name: producer
    depends_on:
      - kafka
    restart: on-failure
    networks:
      - icsnet
    ports:
      - "8000:8000"

  attack-producer:
    build:
      context: ../
      dockerfile: producer/Dockerfile
    container_name: attack-producer
    depends_on:
      - kafka
    restart: on-failure
    networks:
      - icsnet
    ports:
      - "8002:8000"  # separate metrics port
    environment:
      - CSV_FILE_PATH=/app/datasets/swat/attack/SWaT_Dataset_Attack_v0_1.csv
      - METRICS_PORT=8000
    volumes:
      - ../datasets/swat/attack/:/app/datasets/swat/attack/

  kafka-to-influx:
    build:
      context: ../
      dockerfile: consumer/Dockerfile
    environment:
      - INFLUX_TOKEN=admintoken123
    container_name: kafka-to-influx
    depends_on:
      kafka:
        condition: service_healthy
      influxdb:
        condition: service_healthy
      producer:
        condition: service_started
    restart: on-failure
    networks:
      - icsnet

  # ---------- CPU-only (GPU lines removed) ----------
  spark-consumer:
    build:
      context: ../model
    container_name: spark-consumer
    command: ["inference.py"]
    depends_on:
      - producer
    # request all GPUs (requires NVIDIA Container Toolkit / Docker Desktop GPU support)
    #gpus: all
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - SERVICE_NAME=spark-consumer
      - LOG_LEVEL=INFO
    networks:
      - icsnet
    ports:
      - "4040:4040"  # Spark UI
      - "8001:8001"  # Prometheus endpoint
    volumes:
      - ../model/weights:/weights
    labels:
      - "logging=promtail"
      - "app=spark-consumer"

  spark-train:
    build:
      context: ../model
    container_name: spark-train
    command: ["train.py"]
    depends_on:
      - producer
    # request all GPUs (requires NVIDIA Container Toolkit / Docker Desktop GPU support)
    #gpus: all
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - SERVICE_NAME=spark-train
      - LOG_LEVEL=INFO
    networks:
      - icsnet
    ports:
      - "4041:4040"  # Spark UI
    volumes:
      - ../model/weights:/weights
  # --------------------------------------------------

  pattern-miner:
    build:
      context: ../
      dockerfile: streaming/Dockerfile
    container_name: pattern-miner
    depends_on:
      influxdb:
        condition: service_healthy
    networks:
      - icsnet
    environment:
      - INFLUX_TOKEN=${INFLUXDB_TOKEN}

  feature-selection:
    build:
      context: ..
      dockerfile: feature_engineering/Dockerfile
    image: swat-feature-selection
    working_dir: /app/feature_engineering
    volumes:
      - ../datasets:/app/datasets
      - ../feature_selection_results:/app/feature_engineering/feature_selection_results
    command: >
      python feature_selection.py
        --sample-size 50000
        --correlation-threshold 0.98
        --top-features 30
    profiles: ["manual"]

  spark-forecast-influx-init:
    image: influxdb:latest
    depends_on:
      influxdb:
        condition: service_healthy
    command: sh -c 'influx bucket create -n forecasting -o ucs --token ${INFLUXDB_TOKEN} --host http://influxdb:8086 || true'
    networks:
      - icsnet
    restart: no
    environment:
      - INFLUXDB_TOKEN=${INFLUXDB_TOKEN}

  
  spark-forecast:
    build:
      context: ..
      dockerfile: forecasting/Dockerfile
    container_name: spark-forecast
    depends_on:
      - kafka
      - influxdb
      - producer
      - spark-forecast-influx-init
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - INFLUX_TOKEN=${INFLUXDB_TOKEN}
    networks:
      - icsnet
    ports:
      - "4050:4040"
    volumes:
      - ../model/weights:/weights


networks:
  icsnet:
    driver: bridge

volumes:
  kafka_data:
  influxdb_data:
  grafana_data:
  prometheus_data:
