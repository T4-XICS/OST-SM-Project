 OST–SM Project — Explainability Module (Soma Tohidinia)

This branch contains the Explainability Module (XAI) for the OST–SM Project.
The module provides real-time SHAP-based feature importance using a surrogate model that explains the anomaly scores produced by Henrik’s LSTM–VAE model inside the Spark-consumer service. The goal is to make the anomaly detection system interpretable under streaming conditions.

 Architecture Overview

The Explainability module runs as a Kafka consumer and receives two real-time inputs:

windowed sensor features

LSTM–VAE anomaly scores generated by Spark-consumer

It trains a lightweight XGBoost surrogate to approximate the LSTM–VAE scoring function and then computes SHAP attributions for each batch.

Workflow:

Kafka → sensor windows

Spark-consumer (LSTM–VAE) → anomaly scores

Explainability module → surrogate + SHAP attribution

Prometheus → metrics exported

Grafana → dashboards (Heatmap, Top-K, Anomaly Timeline)

 Features Implemented by Soma Tohidinia
1️. Real-Time SHAP Explainability

Consumes sliding-window features from Kafka

Consumes LSTM–VAE anomaly scores from Spark

Trains an XGBoost surrogate model online

Computes SHAP values for each batch

Normalizes and aggregates feature importance

Streams explanations continuously as metrics

Exports metrics:

explain_shap_mean_abs_importance{feature, batch}

explain_topk_features{feature, rank, batch}

2️. Prometheus Metrics Integration

The module exposes all explanation metrics on: http://localhost:9110/metrics
Prometheus automatically scrapes these values using the prometheus.yml configuration.

3️. Grafana Dashboards Built by Soma

Heatmap / State Timeline (SHAP importance across features)

Top-K SHAP feature ranking panel

LSTM–VAE anomaly score timeline (aligned with Spark-consumer)

4️. Surrogate Model Logic

Reads windowed sensor batches from Kafka

Uses LSTM–VAE anomaly scores as training labels

Trains an XGBoost surrogate to approximate the anomaly scoring function

Computes SHAP explanations on the surrogate model for every new batch

This approach enables real-time interpretability without modifying the original LSTM–VAE.

Directory Structure

explainability/
    stream_explain_job.py      → Kafka consumer + SHAP pipeline
    metrics_exporter.py        → Prometheus metrics
    explainer_surrogate.py     → surrogate model + SHAP logic
    features.py                → feature extraction

spark-consumer/
    inference.py               → anomaly score producer (LSTM–VAE)

deployment/
    docker-compose.yml         → service orchestration
    prometheus.yml             → metric scrape config

How to Run the Module

cd deployment
docker compose up -d

2. Access system components

Grafana → http://localhost:3000

Prometheus → http://localhost:9090

Explainability metrics → http://localhost:9110/metrics

Spark-consumer metrics → http://localhost:8001/metrics

Metrics to Check

explain_shap_mean_abs_importance
explain_topk_features
ae_last_anomaly_score
ae_is_anomaly

Author
Soma Tohidinia
Explainability Module – OST–SM Project
GitHub: https://github.com/SomaTohidi

Email: somatohidinia@gmail.com